# TP-CI-CD

## Information g√©n√©rales

Group:
- Adrien Raimbault
- Dziyana Tsetserava
- Muriel Paraire


Langage de programmation choisie:
- Python


## Questions

### 1. Cr√©ez un fichier docker-compose.yml et ajoutez-y un service db s'appuyant sur l'imageDocker postrges:latest.

Nous avons donc cr√©e un service de nom db de mani√®re suivante :
```yml
services:
  db:
    # utiliser la derni√®re image postgres
    image: postgres:latest
    # redemarrer en cas d'√©chec ou de crash
    restart: always
    # prise en compte des valeurs pr√©cis√© par l'utilisateur
    environment:
      - POSTGRES_PASSWORD=${CITY_API_DB_PWD:?error}
      - POSTGRES_USER=${CITY_API_DB_USER?:error}
      - POSTGRES_DB=city_api
    # le port sur lequel on peut joindre la base de donn√©es
    expose:
      - ${CITY_API_DB_PORT:?error}
    volumes:
      # l'endroit de sauvegarde
      - /var/lib/postgres
      # le script pour cr√©er la table city
      - ./db/init.sql:/docker-entrypoint-initdb.d/create_city.sql
      # le script pour ins√©rer les donn√©es
      - ./db/populate.sql:/docker-entrypoint-initdb.d/populate_city.sql
```

Par la suite, nous avons aussi complet√© notre fichier docker-compose.yml pour y ajouter un containeur d√©marrons notre API : 

```yml
  python:
    # le dockerfile pour lancer l'application
    build:
      context: .
      dockerfile: python.dockerfile
    # le fichier d'environnement
    env_file:
      - .env
    # l'api a besoin que la base de donn√©es sois cr√©er pour pouvoir l'utiliser
    depends_on:
      - db
    # le port de l'application d√©fini par l'utilisateur
    ports:
      - ${CITY_API_PORT:?error}:${CITY_API_PORT:?error}
```

### 2. Cr√©ez une base de donn√©es  city_api  avec une table  city  contenant les colonnes suivantes :
- **id** , un entier non sign√© non nul, cl√© primaire de la colonne ;
- ***department_code** , une cha√Æne de caract√®res non nulle ;
- **insee_code** , une cha√Æne de caract√®res ;
- **zip_code** , une cha√Æne de caract√®res ;
- **name** , une cha√Æne de caract√®res non nulle ;
- **lat** , un flottant non nul ;
- **lon** , un flottant non nul.

Pour cr√©er cette table, nous avons opt√© de cr√©er un script *init.sql* que nous passerons √† docker lors de l'initialisation du conteneur. 

Il s'√©x√©cuteras et cr√©eras la table dans la base de donn√©es qui seras popul√© par le script *populate.sql*.

### 3. Dans le langage de votre choix, cr√©ez un service web ayant les sp√©cifications suivantes :
  - `POST /city` avec pour corps de la requ√™te un JSON au format d√©crit plus bas doit retourner un code `201` et enregistrer la ville dans la base de donn√©es ;
  - `GET /city` doit retourner un code `200` avec la liste des villes au format JSON ;
  - `GET /_health` doit retourner un code `204`.

Pour cette API, nous avons choisi d'utiliser [Flask](https://flask.palletsprojects.com/en/2.3.x/), un framework web Python qui permet de d√©marrer rapidement une application web; le but de ce projet n'√©tant pas de passer du temps sur l'application mais sur la partie CI/CD.

Le code de l'application se trouve dans le fichier [application.py](app/application.py).

Voici un diagramme de s√©quence pour r√©sumer les routes :

```mermaid
sequenceDiagram
    actor C as Client
    participant A as API
    participant D as Database
    C->>+A: GET /city
    A->>-C: HTTP 200 OK
    C->>+A: POST /city
    A-->>D: INSERT INTO city
    D-->>A: OK
    A->>-C: HTTP 201 Created
    C->>+A: GET /_health
    A->>-C: HTTP 204 No Content
```


### 4. √âcrivez les tests suivants :
  - un test qui s'assure que l'insertion dans la base de donn√©es fonctionne correctement ;
  - un test qui s'assure que la r√©cup√©ration de la liste des villes fonctionne correctement ;
  - un test qui s'assure que l'endpoint de healthcheck fonctionne correctement.

Concernant les tests, nous avons d√©cid√© d'utiliser [Pytest](https://docs.pytest.org/en/7.4.x/).

Pytest nous permet d'utiliser la commande : 

```bash
python3 -m pytest -c app/tests/pytest.ini
```

Cette commande va trouver toutes les fonctions commen√ßant par *test_* et va essayer de les ex√©cuter.

PS : le fichier [pytest.ini](app/tests/pytest.ini) donne √† pytest la configuration n√©cessaire. Comme nous utilisons une autre base de donn√©es pour les tests (cf. question 7), le fichier *pytest.init* permet de modifier les variables d'environnement et se connecter ainsi vers la base de donn√©es de tests sur un autre port que la base de donn√©es de production.


### 5. √âcrivez un fichier Dockerfile √† la racine de votre projet. Testez que votre image Docker est correcte.

Voici le fichier [python.dockerfile](./python.dockerfile) qui r√©cup√®re l'image python, installe les d√©pendances d'apr√®s le fichier [requirement.txt](./requirements.txt), copie les fichiers pr√©sents dans le dossier *./app* et run l'application.

```yml
FROM python:3.10-alpine

COPY ./requirements.txt /app/requirements.txt

# set workdir to app
WORKDIR /app

# install dependencies
RUN pip install -r requirements.txt

# Copy app folder
COPY ./app /app

# configure the container to run in an executed manner
ENTRYPOINT [ "python" ]

CMD ["application.py" ]
```

PS : Nous utilisons ici une image **python:3.10-alpine** pour diminuer la taille de l'image, les images bas√©s sur alpine √©tants g√©n√©rallement plus l√©g√®res.

### 6. √âcrivez un workflow GitHub Actions ci pour qu'un linter soit ex√©cut√© √† chaque push.

Pour √©crire notre premier workflow, nous nous sommes renseign√©s sur le fonctionnement de Github concernant l'int√©gration continue. Apr√®s quelques recherches, nous avons mis en place un runner h√©berg√© sur l'un de nos serveurs √† Polytech. C'est tr√®s simple √† mettre √† d√©marrer et cela √©vite d'avoir d'√™tre limit√© en temps pendant le fonctionnement de la CI.

Ensuite nous avons ajout√© une action permettant de r√©cup√©rer l'√©tat actuel du projet.

Enfin avant de lancer le linter, nous installons les d√©pendances pour √©viter que Pylint remonte des erreurs li√©s √† cela.

Le fichier [lint_and_test_ci.yml](.github/workflows/lint_and_test_ci.yml) (anciennement *github_ci.yml*) permet de r√©aliser toutes ces √©tapes et d'√©xecuter [pylint](https://pypi.org/project/pylint/) qui failera si le score est inf√©rieur √† 5/10.

```yml
name: GitHub Actions CI
run-name: ${{ github.actor }} is testing out GitHub Actions üöÄ
on: [push]

jobs:
  python-ci:
    runs-on: self-hosted
    steps:
          - uses: actions/checkout@v3

          - name: Install dependencies
            run: |
              python3 -m pip install --upgrade pip
              pip3 install pytest
              pip3 install pylint
              if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

          - name: Analysing the code with pylint
                  run: |
                    pylint --fail-under=5 app/*
```

### 7. Modifiez le workflow pour que les tests s'ex√©cutent √† chaque push.

#### Solution N¬∞1

Ici les tests ont d√©j√† √©t√© √©crits. Il ne reste plus qu'√† les inclure dans le workflow.

La premi√®re id√©e que nous avons eu √©tait de cr√©er un duplicat de notre base de donn√©es postgres (nomm√©e "postgres-test") qui serait lanc√© avec la commande

```bash
docker compose up postgres-test
```

Lors des tests nous avons eu des probl√®mes pour connecter la base de donn√©es et l'application. L'application se lan√ßait apr√®s la base de donn√©es mais pas assez tard pour que la base de donn√©es puisse accepter la connexion.

#### Solution N¬∞2

Apr√®s renseignement, nous avons d√©couvert les [services](https://docs.github.com/en/actions/using-containerized-services/about-service-containers). Ils permettent de lancer des conteneurs docker et sont g√©r√©s par le workflow. Ils sont tr√®s configurables et permettent de pr√©parer le "terrain" avant de lancer le workflow.

Apr√®s impl√©mentation de cette id√©e, voici notre workflow (fichier [lint_and_test_ci.yml](.github/workflows/lint_and_test_ci.yml)) : 

```yml
name: GitHub Actions CI
run-name: ${{ github.actor }} is testing out GitHub Actions üöÄ
on: [push]

jobs:
  python-ci:
    runs-on: self-hosted
    # Service containers to run with `container-job`
    services:
      postgres-test:
        image: postgres
        # Provide the env for postgres
        env:
          POSTGRES_PASSWORD: test
          POSTGRES_USER: test
          POSTGRES_HOST: localhost
          POSTGRES_PORT: 5436
          POSTGRES_DB: city_api
        # Set health checks to wait until postgres has started
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          # Maps tcp port 5432 on service container to port 5436 on the host
          - 5436:5432

    steps:
      - uses: actions/checkout@v3

      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          pip3 install pytest
          pip3 install pylint
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Analysing the code with pylint
        run: |
          pylint --fail-under=5 app/*
      
      - name: Testing code
        run: |
          psql -U test city_api -h localhost -p 5436 -f db/init.sql
          python3 -m pytest -c app/tests/pytest.ini
        env:
          PGPASSWORD: test

      - run: echo "üçè This job's status is ${{ job.status }}."
```

### 8. Modifiez le workflow pour qu'un build de l'image Docker soit r√©alis√© √† chaque push.

N'ayant pas d'id√©e pour build l'image, nous avons fait des recherches et sommes tomb√©s sur le marketplace de Github.

Le market place offre des actions pr√©fabriqu√©es pour simplifier le travail d'int√©gration continue avec Github. Nous avons d√©cid√©s d'utiliser une action officielle de docker : `docker/build-push-action@v4`.
Cette action permet de build l'image docker et de la push sur le registry desir√©e, ce qui nous permet de r√©aliser la question 8 & 9 en m√™me temps.

Voici le job d√©di√© au build et au push :

```yml
name: GitHub Release CI
run-name: ${{ github.actor }} is testing out GitHub Actions üöÄ

on: [push]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository_owner }}/city-api

jobs:
  build:
    name: Build Docker image
    runs-on: self-hosted
    permissions:
      packages: write
    steps:
      - uses: actions/checkout@v3
        name: Check out the repository

      - uses: docker/login-action@v2
        name: Log in to the container registry
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - uses: docker/build-push-action@v4
        name: Build and push the Docker image
        with:
          file: python.dockerfile
          push: true
```

#### Remarques :
  - On sp√©cifie dans les variables d'environnement la registry utilis√©e pour push l'image (ghcr.io ici).
  - Il est n√©cessaire de se connecter en amont via l'action `docker/login-action@v2`. Cette action cr√©e un token d'authentification `GITHUB_TOKEN` (ou utilise celui existant le cas ech√©ant) pour se connecter √† la registry de Github.

### 9. Modifiez le workflow pour que l'image Docker soit push sur ghcr.io avec pour tag city-api:latest.

Nous avons pr√©c√©demment build & push l'image docker. Pour rajouter un tag nous pouvons simplement le pr√©ciser avec l'argument `tags` :

```yml
- uses: docker/build-push-action@v4
        name: Build and push the Docker image
        with:
          file: python.dockerfile
          push: true
          tags: [latest]
```

### 10. √âcrivez un workflow GitHub Actions release qui, lorsqu'un tag au format vX.X.X soit pouss√© build et push l'image Docker avec un tag city-api:X.X.X.

On veut maintenant pouvoir passer un tag *version*. Le but est que si le commit ne contient pas de tag au format *vX.X.X*, l'image n'est ni build ni push.
Pour cela, il suffit juste de modifier le d√©clancheur (trigger) pour le lancer seulement un un tag au format *vX.X.X* est pr√©sent :

```yml
on:
  push:
    tags:
      - 'v*.*.*'
```

Ensuite il faut donner le m√™me tag √† l'image push sur la registry Github. 
On utilise ici une autre action officielle docker : `docker/metadata-action@v4`. Elle permet d'extraire les tags d'un commit.

Il suffit de rajouter un bloc dans notre fichier :

```yml
- uses: docker/metadata-action@v4
        name: Extract metadata (tags, labels) for Docker
        id: meta
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=semver,pattern={{version}}
            latest
```

Enfin on modifie la ligne *tags* pour ajouter √† l'image les m√™me tags :


```yml
- uses: docker/build-push-action@v4
      name: Build and push the Docker image
      with:
        file: python.dockerfile
        push: true
        tags: ${{ steps.meta.outputs.tags }}
```

### 11) Installez Minikube sur votre machine local.

Pour installer minikube on peut suivre la documentation √† [https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/)

```sh
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube
```
Pour lancer minikube il suffit d'utiliser la commande 
```sh
minikube start
```

### 12) √âcrivez un chart Helm de d√©ploiement de l'application.

#### Install helm :

Official documentation : https://helm.sh/docs/intro/install/


Use the chart helm : 
```
helm install <name> <path_to_helm_directory>
```

Stop it :
```
helm uninstall <name>
```

At the moment, the API is accessible from outside the Cluster, however if you wish to change that you can simply change the type of service to ClusterIP.
```yaml
service:
  type: NodePort # change to ClusterIP to block access from outside the Clutser
```

The username and password for the database are set in the city-api/values.yaml file, you are free to change them.


### 13) D√©ployez votre application dans votre Minikube.


To deploy the chart helm, simply run
```
helm install city-api ./city-api
```

14) Ajouter un endpoint `/metrics` compatible Prometheus (des [libs](https://sysdig.com/blog/prometheus-metrics/) sont disponibles).

15) Ajoutez un Prometheus dans votre docker-compose qui scrappe les m√©triques de votre application.

16) Ajoutez un Grafana dans votre docker-compose et cr√©ez y un dahsboard pour monitorer votre application
